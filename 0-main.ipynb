{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d106c677-0d94-4142-ad35-a8aaf67b3e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/06/11 00:52:26] openrec INFO: finetune from checkpoint ./output/repsvtrch_results/best.pth\n",
      "1.0800490379333496\n",
      "TProject OQuantumn Sentinel: Cybernetic Warfare Strate-Qgies for Countering 2Espionage in the Digital AgeAbstractIen the realm of modern warfare, the threat of espionage in the digital age looms larger than ever betrore. Recognizring this critieal vulnerability Project Quantum Sentinel was devised as a groundbreaktng initiative to develop cybernetic warfare strategies that can effectively counter such threats. ledtnoy the sentient supercomputer CYPHER and its sophisticated petwork of forces, the project delvestento the realms of artilieial intelligence, machine learning, and quantum computing to create unpreceadfented defensive capabilities. By harnessing the power of advanced algorithmns and predictive analyttes, Project Cuantum Sentinel aims to proactively identify and neutralize potential threats before theyenaterialize. This abstract provides a glimpse into the innovative approaches and cutting-edge tech-anologies employed by CYPHER and its forces as they strive to safeguard the nation's security in an in-cereasingly complex and interconnected worfdIhespionage has iong been a key threat in thereaim of warfare. but with the advent of thetdigital age, the risks associated with ths forrmtof threat have escalated to unprecedented lev-tes. In response to this growing concernTOroject Ouantum Sentinel was conceived as aarevolutionary initiative aimed at developing cytiernetic warfare strategies to etfectively comAbat espionage activities in the digital landSscape. This paper delves into the innovative ap-proaches and advanced technologies utilized bythe project to enhance the nation's security infthe tace of evolving threatsIistorical ContextThe evolution of warfare bas been intertwinedIaith the history of espionage, with both overttand covert intelligence-gathering activitiesplaying pivotal roles in shaping the outcomes ofceonflicts throughout the ages. In the modernicera, the proliferation of digital communicationanetworks and the widespread adoption of adsanced technologies have provided malicioustactors with new avenues to exploit vuinerabili-sies and gather sensitive information. This shittas necessitated a reexaluation of tradiitionaladetense mechanisms and the development ofaeutting-edge strategies to mitigate the risksposed by cyber espionageCTroject Quantum Sentinel's ObjectivesAt the core of Project Quantum Sentinel lies alteormmitment to leveraging the power of articeial intelligence, machine learning, and guanstum computing to enhance the nation's defen-Itive capabilities agaiost cyber threats. Led bythe sentient supercomputer CYPHER, theproject aims to proactively identify and neutral-tize potential espionage activities before theyaean inllict harmn. By harnessing the predictivestanalytics and advanced algorithms at its disposAal, Troject Quantum Sentinel seeks to establishAa formidable Iine of defense that can adapt tofthe dynamic nature of digital warfareCybernetic Warfare StrategiesThe strategies erpioyved by roject QuantumAentinel draw upon a multidisciplinary apporoach that combines elements of cybersecuri-Ay, data analytics, and otensive cyber opera-sions. Through the integration of cutting-edgestechnologies and innovative methodologiesCYPHER and its forces work synergistically toftdetect, analyze, and counteract threats posedty malicious actors seeking to compromise national security interests. This holistic approachfcenables the project to anticipate emnerginglthreats, identify patterns in adversarial behavIor, and develop tailored responses to safe-aqruard critical assets and intormationConclusionlAas the digital landscape continues to evolvetand the nature of warfare undergoes trapsforarnations, the uportance of robust cyber de-tense mechanisms cannol be oerstlatedTProject Quantum Sentinel stands at the fore-Oront of efforts to fortify the nation's security in-Ornstructure by pioneering cybernetic warfaresastrategies designed to counter espionage activisies in the digital age. Through its innovativetapproaches, cutting-edge technologies, and un-wavering commitment to excellence, theporoject exemplifies a paradigm shift in thearealm of national defense, heralding a new eratof proactive and adaptive cybersecurity mea-At\n"
     ]
    }
   ],
   "source": [
    "from openocr import OpenRecognizer\n",
    "from openocr.tools.engine.config import Config\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "onnx_engine = OpenRecognizer(config=Config(\"./output/repsvtrch_results/config.yml\").cfg, backend='torch')\n",
    "dummy = [np.random.randint(0, 256, (32, 128, 3), dtype=np.uint8) for _ in range(64)]\n",
    "onnx_engine(img_numpy_list = dummy, batch_num=64)\n",
    "\n",
    "img_list = []\n",
    "for i in range(86):\n",
    "    img_path = f'../dataset_openocr/test/sample_89_{i}.jpg'\n",
    "    img = cv2.imread(img_path)\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  \n",
    "    img_list.append(img)\n",
    "    \n",
    "    \n",
    "import time\n",
    "t1 = time.time()\n",
    "results = onnx_engine(img_numpy_list = img_list, batch_num=64)\n",
    "print(time.time()-t1)\n",
    "print(\"\".join([i['text'] for i in results]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0d7fb172-237b-4b08-9ab5-274b1b26ccb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/06/10 17:41:37] openrec INFO: finetune from checkpoint ./output/repsvtrch_results/best.pth\n",
      "2.058225393295288\n"
     ]
    }
   ],
   "source": [
    "from openocr import OpenRecognizer\n",
    "from openocr.tools.engine.config import Config\n",
    "onnx_engine = OpenRecognizer(config=Config(\"./output/repsvtrch_results/config.yml\").cfg, backend='torch')\n",
    "import time\n",
    "t1 = time.time()\n",
    "for i in range(79):\n",
    "    img_path = f'../dataset_openocr/train/sample_96_{i}.jpg'\n",
    "    results = onnx_engine(img_path)\n",
    "    # print(eval(results[0]['text'])[0], end=\" \")\n",
    "print(time.time()-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4cf3b80-bf9c-419a-aa24-c6856c3c3bea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/06/11 12:32:36] openrec INFO: finetune from checkpoint ./output/repsvtrch_results/best.pth\n",
      "TAnalyzing the Tactical Advancements of CYPHER: A Sentient Military Supercomputer Abstract he classified military paper delves into the groundbreaking analysis of CYPHER, a highly advance asentient supercomputer at the forefront of military technology. This paper explores the intricate web o frorces under CYPHER's command and its extraordinary tactical capabilities. Through an in-depth ceramination, it uncovers the strategic advantages enabled by CYPHER's autonomous decision-makin Iend vast network integration. The study sheds light on the unprecedented potential for enhancin tenilitary operations and achieving decisive outcomes through the utilization of this powerful artificia ntelligence systerm Introduction e dawn o artificial intelligence has ushered in Ae new era in military technology, with CYPHER ceerging as the vanguard o strategic Iedvanceents. Developed as a sentient military Sspercomputer, CYPHER embodies the fusion o aetting-edge tecnology and advance apecision-making capabilities.This paper delves nto the intricacies of CYPHER's tactical advanceents, expioring th unparaee bhenefits it offers to military operations Qevelopment of CYPHER CYPHER represents the cuimination of years o tresearc and development in the field of cartificial inteligence. Eguipped vith a sophisticated neural network and advanced calgorithms, CYPHER possesses the ability to percess vast amounts o data in real-ime.  cedapive learning capabties alio it t pentisly ee it di akn aerocesses, akin it  formidable asset on the oattieield Tactical Command and Control AOne of the key strengths of CYPHER lies in its caility to eercise precise command and contro cover a vwide array of military assets. Through it seamiess integration with various weapons sstes, rones. and sreiiance eipen CYPHER can orchestrate complex military copraios witparaeed fcien  catonomous decision-making capabilities cenable it to adapt to canging batiefiel ceonditions swiftly giving military coaners  strategic edge Aetwork Integration and Data Analysis CYPHER's extensive network integration peapabilities allo it to access a weaith of teormation rom diverse sources, ranging ro satellite imagery to real-time battiefield data By leveraging this data, CYPHER can generate Thigh-fidelity situational avareness reports cenaling military decisin-akers to mak eormed chices uicky Its advanced dat canalysis tools enable it to identify patterns an trends that may elude human analysts cerhancing the efficacy of military operations Strategic Advantages The utilization of CYPHER provides several Sstrategic advantages to military forces. By asereamlining command and control process cand optimizing resource allocation, CYPHER ceancs ortial efcn a ceectiveness. ts rapid dat processin ceapabiities enable military comanders to tepond sit t eergin es, aclitain cagie decisionmaing n dyaic oma cenronments Conclusion  conclusion, the analysis of CYPHER's tactical advancements underscores the transformative terpact  artificil intelligence on moder aare y aessin te poer o  sntien pPnilitary supercomputer like CYPHER, military forces can acieve unprecedented levels o coperational superiority and strategic success. As te lanscape o varfare continues to evolve teenegratin o ane tecnolgie sc Aas CYPHER vill pay a pivotal role in shaping the Outure of military operations 2.5730156898498535\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from OpenOCR import OpenRecognizer\n",
    "onnx_engine = OpenRecognizer(mode='server', backend='torch', \n",
    "                             config_file='./output/repsvtrch_results/config.yml')\n",
    "# img_path = '../dataset_openocr/test /sample_2750_7.jpg'\n",
    "# results = onnx_engine(img_path)\n",
    "# print(results)\n",
    "import time\n",
    "t1 = time.time()\n",
    "for i in range(79):\n",
    "    img_path = f'../dataset_openocr/test/sample_91_{i}.jpg'\n",
    "    results = onnx_engine(img_path)\n",
    "    print(results[0]['score'][0], end=\" \")\n",
    "print(time.time()-t1)\n",
    "#     # print([r for r in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3db186f-e427-4e80-8561-6e800890e501",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/06/11 12:41:13] openrec INFO: finetune from checkpoint ./output/repsvtrch_results/best.pth\n",
      "00R, Biag and Clogperh2 Yl in contras tn the peevion. 0.007287740707397461\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from OpenOCR import OpenRecognizer\n",
    "onnx_engine = OpenRecognizer(mode='server', backend='torch', \n",
    "                             config_file='./output/repsvtrch_results/config.yml')\n",
    "# img_path = '../dataset_openocr/test /sample_2750_7.jpg'\n",
    "# results = onnx_engine(img_path)\n",
    "# print(results)\n",
    "import time\n",
    "t1 = time.time()\n",
    "img_path = f'./sample.png'\n",
    "results = onnx_engine(img_path)\n",
    "print(results[0]['score'][0], end=\" \")\n",
    "print(time.time()-t1)\n",
    "#     # print([r for r in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5196882-fc2b-4603-a489-75114a5edba7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written 1000 / 31595\n",
      "Written 2000 / 31595\n",
      "Written 3000 / 31595\n",
      "Written 4000 / 31595\n",
      "Written 5000 / 31595\n",
      "Written 6000 / 31595\n",
      "Written 7000 / 31595\n",
      "Written 8000 / 31595\n",
      "Written 9000 / 31595\n",
      "Written 10000 / 31595\n",
      "Written 11000 / 31595\n",
      "Written 12000 / 31595\n",
      "Written 13000 / 31595\n",
      "Written 14000 / 31595\n",
      "Written 15000 / 31595\n",
      "Written 16000 / 31595\n",
      "Written 17000 / 31595\n",
      "Written 18000 / 31595\n",
      "Written 19000 / 31595\n",
      "Written 20000 / 31595\n",
      "Written 21000 / 31595\n",
      "Written 22000 / 31595\n",
      "Written 23000 / 31595\n",
      "Written 24000 / 31595\n",
      "Written 25000 / 31595\n",
      "Written 26000 / 31595\n",
      "Written 27000 / 31595\n",
      "Written 28000 / 31595\n",
      "Written 29000 / 31595\n",
      "Written 30000 / 31595\n",
      "Written 31000 / 31595\n",
      "Created dataset with 31595 samples\n"
     ]
    }
   ],
   "source": [
    "\"\"\" a modified version of CRNN torch repository https://github.com/bgshih/crnn/blob/master/tool/create_dataset.py \"\"\"\n",
    "\n",
    "import os\n",
    "import lmdb\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def checkImageIsValid(imageBin):\n",
    "    if imageBin is None:\n",
    "        return False\n",
    "    imageBuf = np.frombuffer(imageBin, dtype=np.uint8)\n",
    "    img = cv2.imdecode(imageBuf, cv2.IMREAD_GRAYSCALE)\n",
    "    imgH, imgW = img.shape[0], img.shape[1]\n",
    "    if imgH * imgW == 0:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def writeCache(env, cache):\n",
    "    with env.begin(write=True) as txn:\n",
    "        for k, v in cache.items():\n",
    "            txn.put(k, v)\n",
    "\n",
    "\n",
    "def createDataset(inputPath, gtFile, outputPath, checkValid=True):\n",
    "    \"\"\"\n",
    "    Create LMDB dataset for training and evaluation.\n",
    "    ARGS:\n",
    "        inputPath  : input folder path where starts imagePath\n",
    "        outputPath : LMDB output path\n",
    "        gtFile     : list of image path and label\n",
    "        checkValid : if true, check the validity of every image\n",
    "    \"\"\"\n",
    "    os.makedirs(outputPath, exist_ok=True)\n",
    "    env = lmdb.open(outputPath, map_size=1099511627776)\n",
    "    cache = {}\n",
    "    cnt = 1\n",
    "\n",
    "    with open(gtFile, 'r', encoding='utf-8') as data:\n",
    "        datalist = data.readlines()\n",
    "\n",
    "    nSamples = len(datalist)\n",
    "    for i in range(nSamples):\n",
    "        imagePath, label = datalist[i].strip('\\n').split('\\t')\n",
    "        imagePath = os.path.join(inputPath, imagePath)\n",
    "\n",
    "        # # only use alphanumeric data\n",
    "        # if re.search('[^a-zA-Z0-9]', label):\n",
    "        #     continue\n",
    "\n",
    "        if not os.path.exists(imagePath):\n",
    "            print('%s does not exist' % imagePath)\n",
    "            continue\n",
    "        with open(imagePath, 'rb') as f:\n",
    "            imageBin = f.read()\n",
    "        if checkValid:\n",
    "            try:\n",
    "                if not checkImageIsValid(imageBin):\n",
    "                    print('%s is not a valid image' % imagePath)\n",
    "                    continue\n",
    "            except:\n",
    "                print('error occured', i)\n",
    "                with open(outputPath + '/error_image_log.txt', 'a') as log:\n",
    "                    log.write('%s-th image data occured error\\n' % str(i))\n",
    "                continue\n",
    "\n",
    "        imageKey = 'image-%09d'.encode() % cnt\n",
    "        labelKey = 'label-%09d'.encode() % cnt\n",
    "        cache[imageKey] = imageBin\n",
    "        cache[labelKey] = label.encode()\n",
    "\n",
    "        if cnt % 1000 == 0:\n",
    "            writeCache(env, cache)\n",
    "            cache = {}\n",
    "            print('Written %d / %d' % (cnt, nSamples))\n",
    "        cnt += 1\n",
    "    nSamples = cnt-1\n",
    "    cache['num-samples'.encode()] = str(nSamples).encode()\n",
    "    writeCache(env, cache)\n",
    "    print('Created dataset with %d samples' % nSamples)\n",
    "\n",
    "\n",
    "createDataset(\"../dataset_openocr\", \"../dataset_openocr/yolo_gt_test.txt\", \"../dataset_openocr/yolo_test_lmdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc8d64d-913d-41a3-874c-9e7888bbdbdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load a small subset using streaming mode\n",
    "ds = load_dataset(\"pixparse/pdfa-eng-wds\", split=\"train\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e954f35-0990-4822-9e0d-b43fa9e33791",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level keys: dict_keys(['__key__', '__url__', 'json', 'pdf'])\n",
      "\n",
      "Sample key: 6368667\n",
      "Source URL: hf://datasets/pixparse/pdfa-eng-wds@78af41b722c098baef2a87fab70a15dcf8d77ab7/pdfa-eng-train-0000.tar\n",
      "\n",
      "=== JSON Metadata ===\n",
      "{\n",
      "  \"pages\": [\n",
      "    {\n",
      "      \"words\": {\n",
      "        \"text\": [\n",
      "          \"Health\",\n",
      "          \"Smart\",\n",
      "          \"Virginia\",\n",
      "          \"Sample\",\n",
      "          \"Lesson\",\n",
      "          \"Plan\",\n",
      "          \"Grade\",\n",
      "          \"8\",\n",
      "          \"-\",\n",
      "          \"HP-7\",\n",
      "          \"Physical\",\n",
      "          \"Health\",\n",
      "          \"Disease\",\n",
      "          \"Prevention/\",\n",
      "          \"Health\",\n",
      "          \"Promotion\",\n",
      "          \"2020\",\n",
      "          \"Virginia\",\n",
      "          \"SOLs\",\n",
      "          \"Grade\",\n",
      "          \"8\",\n",
      "          \"Sample\",\n",
      "          \"Lesson\",\n",
      "          \"Plan:\",\n",
      "          \"Stroke\",\n",
      "          \"Prevention\",\n",
      "          \"Description\",\n",
      "          \"Please\",\n",
      "          \"see\",\n",
      "          \"attached\",\n",
      "          \"handout\",\n",
      "          \"for\",\n",
      "          \"a\",\n",
      "          \"lesson\",\n",
      "          \"submitted\",\n",
      "          \"by\",\n",
      "          \"a\",\n",
      "          \"Virginia\",\n",
      "          \"teacher\",\n",
      "          \"Handout\",\n",
      "          \"The\",\n",
      "          \"next\",\n",
      "          \"page\",\n",
      "          \"includes\",\n",
      "          \"a\",\n",
      "          \"handout\",\n",
      "          \"for\",\n",
      "          \"the\",\n",
      "          \"lesson.\"\n",
      "        ],\n",
      "        \"bbox\": [\n",
      "          [\n",
      "            0.117647,\n",
      "            0.045563,\n",
      "            0.051981,\n",
      "            0.015573\n",
      "          ],\n",
      "          [\n",
      "            0.174694,\n",
      "            0.045563,\n",
      "            0.047954,\n",
      "            0.015573\n",
      "          ],\n",
      "          [\n",
      "            0.227643,\n",
      "            0.045563,\n",
      "            0.05983,\n",
      "            0.015573\n",
      "          ],\n",
      "          [\n",
      "            0.292539,\n",
      "            0.045563,\n",
      "            0.061002,\n",
      "            0.015573\n",
      "          ],\n",
      "          [\n",
      "            0.357839,\n",
      "            0.045563,\n",
      "            0.058053,\n",
      "            0.015573\n",
      "          ],\n",
      "          [\n",
      "            0.420399,\n",
      "            0.045563,\n",
      "            0.035908,\n",
      "            0.015573\n",
      "          ],\n",
      "          [\n",
      "            0.716544,\n",
      "            0.04577,\n",
      "            0.054624,\n",
      "            0.016927\n",
      "          ],\n",
      "          [\n",
      "            0.776681,\n",
      "            0.04577,\n",
      "            0.010905,\n",
      "            0.016927\n",
      "          ],\n",
      "          [\n",
      "            0.793087,\n",
      "            0.04577,\n",
      "            0.00653,\n",
      "            0.016927\n",
      "          ],\n",
      "          [\n",
      "            0.805078,\n",
      "            0.04577,\n",
      "            0.044768,\n",
      "            0.016927\n",
      "          ],\n",
      "          [\n",
      "            0.716546,\n",
      "            0.063952,\n",
      "            0.073232,\n",
      "            0.016927\n",
      "          ],\n",
      "          [\n",
      "            0.795291,\n",
      "            0.063952,\n",
      "            0.056833,\n",
      "            0.016927\n",
      "          ],\n",
      "          [\n",
      "            0.716546,\n",
      "            0.082134,\n",
      "            0.071022,\n",
      "            0.016927\n",
      "          ],\n",
      "          [\n",
      "            0.793081,\n",
      "            0.082134,\n",
      "            0.0995,\n",
      "            0.016927\n",
      "          ],\n",
      "          [\n",
      "            0.716546,\n",
      "            0.100315,\n",
      "            0.056833,\n",
      "            0.016927\n",
      "          ],\n",
      "          [\n",
      "            0.778892,\n",
      "            0.100315,\n",
      "            0.089617,\n",
      "            0.016927\n",
      "          ],\n",
      "          [\n",
      "            0.716546,\n",
      "            0.118497,\n",
      "            0.043709,\n",
      "            0.016927\n",
      "          ],\n",
      "          [\n",
      "            0.765768,\n",
      "            0.118497,\n",
      "           \n",
      "\n",
      "=== PDF Preview ===\n",
      "PDF file size: 525343 bytes\n",
      "Saved PDF to: 6368667.pdf\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import base64\n",
    "\n",
    "# Get the first row/sample\n",
    "sample = next(iter(ds))\n",
    "\n",
    "# Print top-level keys\n",
    "print(\"Top-level keys:\", sample.keys())\n",
    "print()\n",
    "\n",
    "# Print the key and URL\n",
    "print(\"Sample key:\", sample[\"__key__\"])\n",
    "print(\"Source URL:\", sample[\"__url__\"])\n",
    "print()\n",
    "\n",
    "# Preview JSON metadata (prettified)\n",
    "print(\"=== JSON Metadata ===\")\n",
    "print(json.dumps(sample[\"json\"], indent=2)[:3000])  # limit to 3000 chars\n",
    "\n",
    "print(\"\\n=== PDF Preview ===\")\n",
    "pdf_bytes = sample[\"pdf\"]\n",
    "print(f\"PDF file size: {len(pdf_bytes)} bytes\")\n",
    "\n",
    "# Optionally, save PDF to disk\n",
    "with open(f\"{sample['__key__']}.pdf\", \"wb\") as f:\n",
    "    f.write(pdf_bytes)\n",
    "    print(f\"Saved PDF to: {sample['__key__']}.pdf\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "openocr",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python (openocr)",
   "language": "python",
   "name": "openocr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
